{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Redes Neurais e Deep Learning \u2014 Insper","text":"<p>Este portf\u00f3lio re\u00fane as atividades e projetos desenvolvidos na disciplina de Redes Neurais e Deep Learning do Insper. O objetivo \u00e9 documentar de forma clara e organizada cada etapa do aprendizado, desde os primeiros conceitos de separabilidade de dados at\u00e9 a implementa\u00e7\u00e3o de modelos mais avan\u00e7ados, como redes neurais multicamadas e modelos generativos.</p> <p>Ao longo deste material, est\u00e3o descritos:</p> <ul> <li>A motiva\u00e7\u00e3o de cada exerc\u00edcio ou projeto,</li> <li>O passo a passo de implementa\u00e7\u00e3o,</li> <li>As an\u00e1lises dos resultados obtidos,</li> <li>E as conclus\u00f5es em rela\u00e7\u00e3o ao uso de redes neurais para diferentes problemas.</li> </ul>"},{"location":"#estrutura-do-portfolio","title":"Estrutura do Portf\u00f3lio","text":""},{"location":"#exercicios","title":"\ud83d\udcdd Exerc\u00edcios","text":"<p>Os exerc\u00edcios pr\u00e1ticos t\u00eam como foco a explora\u00e7\u00e3o de conceitos fundamentais de redes neurais.  </p> <ol> <li>Data \u2014 Gera\u00e7\u00e3o e an\u00e1lise de dados sint\u00e9ticos para explorar separabilidade de classes e limites de decis\u00e3o.  </li> <li>Perceptron \u2014 Implementa\u00e7\u00e3o e avalia\u00e7\u00e3o de um perceptron simples para problemas linearmente separ\u00e1veis.  </li> <li>MLP (Multi-Layer Perceptron) \u2014 Constru\u00e7\u00e3o e treinamento de uma rede neural multicamadas para lidar com problemas n\u00e3o lineares.  </li> <li>Metrics \u2014 An\u00e1lise de m\u00e9tricas de avalia\u00e7\u00e3o, discutindo acur\u00e1cia, precis\u00e3o, recall e F1-score no contexto de classifica\u00e7\u00e3o.</li> </ol>"},{"location":"#projetos","title":"\ud83d\ude80 Projetos","text":"<p>Os projetos aplicam os conceitos estudados em problemas mais complexos e realistas.  </p> <ol> <li>Classification \u2014 Modelos de classifica\u00e7\u00e3o em diferentes conjuntos de dados, explorando arquiteturas de redes neurais.  </li> <li>Regression \u2014 Aplica\u00e7\u00e3o de redes neurais em tarefas de regress\u00e3o, analisando desempenho e capacidade de generaliza\u00e7\u00e3o.  </li> <li>Generative Models \u2014 Estudo e implementa\u00e7\u00e3o de modelos generativos (como autoencoders ou GANs), avaliando seu potencial em criar ou reconstruir dados.</li> </ol>"},{"location":"#status-de-desenvolvimento","title":"\ud83d\udccc Status de Desenvolvimento","text":"<ul> <li> Exerc\u00edcio 1 (Data) conclu\u00eddo e documentado.  </li> <li>[] Exerc\u00edcio 2 (Perceptron) conclu\u00eddo e documentado.  </li> <li>[] Exerc\u00edcio 3 (MLP) conclu\u00eddo e documentado.  </li> <li>[] Exerc\u00edcio 4 (Metrics) conclu\u00eddo e documentado.  </li> <li>[] Projeto 1 (Classification) em andamento.  </li> <li>[] Projeto 2 (Regression) em andamento.  </li> <li>[] Projeto 3 (Generative Models) planejado para pr\u00f3xima etapa.  </li> </ul>"},{"location":"#conclusao","title":"\ud83c\udfaf Conclus\u00e3o","text":"<p>Este portf\u00f3lio funciona como um di\u00e1rio de bordo da disciplina, mostrando n\u00e3o apenas os c\u00f3digos implementados, mas tamb\u00e9m as reflex\u00f5es sobre os resultados e os aprendizados obtidos. A ideia \u00e9 que ele sirva como refer\u00eancia tanto para revisitar conceitos importantes quanto para inspirar futuros trabalhos na \u00e1rea de Intelig\u00eancia Artificial aplicada a Redes Neurais.</p>"},{"location":"data/exercicio1/exercicio1/","title":"Exerc\u00edcio 1 \u2014 Data","text":""},{"location":"data/exercicio1/exercicio1/#objetivo","title":"Objetivo","text":"<p>O objetivo deste exerc\u00edcio foi gerar um conjunto de dados sint\u00e9ticos em 2 dimens\u00f5es para analisar sua separabilidade entre classes. Esse processo \u00e9 importante porque ajuda a entender como uma rede neural simples ou mais profunda teria que se adaptar para classificar os dados corretamente.</p>"},{"location":"data/exercicio1/exercicio1/#etapa-1-geracao-dos-dados-sinteticos","title":"Etapa 1 \u2014 Gera\u00e7\u00e3o dos Dados Sint\u00e9ticos","text":"<p>O objetivo desta etapa foi criar um conjunto de dados bidimensionais (vari\u00e1veis <code>x1</code> e <code>x2</code>) divididos em 4 classes distintas, cada uma com 100 pontos, totalizando 400 amostras.</p> <p>Para garantir reprodutibilidade, defini a semente do gerador de n\u00fameros aleat\u00f3rios (<code>np.random.seed(42)</code>), o que faz com que os mesmos pontos sejam gerados a cada execu\u00e7\u00e3o do c\u00f3digo.</p> <p>Cada classe foi gerada usando a fun\u00e7\u00e3o <code>np.random.normal</code>, que amostra valores de uma distribui\u00e7\u00e3o normal (gaussiana) a partir de um valor m\u00e9dio (<code>loc</code>) e um desvio padr\u00e3o (<code>scale</code>). Assim:</p> <ul> <li>Classe 0: centrada em (2, 3), mais espalhada no eixo y (<code>scale=2.5</code>).  </li> <li>Classe 1: centrada em (5, 6), com varia\u00e7\u00e3o moderada em ambos os eixos.  </li> <li>Classe 2: centrada em (8, 1), compacta em torno da m\u00e9dia.  </li> <li>Classe 3: centrada em (15, 4), bem concentrada em <code>x1</code> mas com maior varia\u00e7\u00e3o em <code>x2</code>.</li> </ul> <p>Por fim, usei <code>np.column_stack</code> para juntar as duas vari\u00e1veis (<code>x1</code>, <code>x2</code>) em um array bidimensional, representando os pontos de cada classe.</p> <pre><code>np.random.seed(42)  \nn = 100\n\n# Classe 0\nc0_x1 = np.random.normal(loc=2, scale=0.8, size=n)\nc0_x2 = np.random.normal(loc=3, scale=2.5, size=n)\nc0 = np.column_stack((c0_x1, c0_x2))\n\n# Classe 1\nc1_x1 = np.random.normal(loc=5, scale=1.2, size=n)\nc1_x2 = np.random.normal(loc=6, scale=1.9, size=n)\nc1 = np.column_stack((c1_x1, c1_x2))\n\n# Classe 2\nc2_x1 = np.random.normal(loc=8, scale=0.9, size=n)\nc2_x2 = np.random.normal(loc=1, scale=0.9, size=n)\nc2 = np.column_stack((c2_x1, c2_x2))\n\n# Classe 3\nc3_x1 = np.random.normal(loc=15, scale=0.5, size=n)\nc3_x2 = np.random.normal(loc=4, scale=2.0, size=n)\nc3 = np.column_stack((c3_x1, c3_x2))\n</code></pre>"},{"location":"data/exercicio1/exercicio1/#etapa-2-visualizacao-dos-dados","title":"Etapa 2 \u2014 Visualiza\u00e7\u00e3o dos Dados","text":"<p>Com as quatro classes j\u00e1 geradas, o pr\u00f3ximo passo foi visualizar a distribui\u00e7\u00e3o dos pontos em um gr\u00e1fico de dispers\u00e3o (scatter plot).</p> <p>Esse gr\u00e1fico \u00e9 essencial porque permite observar a separabilidade entre classes e j\u00e1 adianta poss\u00edveis regi\u00f5es de sobreposi\u00e7\u00e3o que precisaremos analisar na pr\u00f3xima etapa.</p> <pre><code>plt.figure(figsize=(7,5))\nplt.scatter(c0[:,0], c0[:,1], label=\"Class 0\", s=18, alpha=0.8)\nplt.scatter(c1[:,0], c1[:,1], label=\"Class 1\", s=18, alpha=0.8)\nplt.scatter(c2[:,0], c2[:,1], label=\"Class 2\", s=18, alpha=0.8)\nplt.scatter(c3[:,0], c3[:,1], label=\"Class 3\", s=18, alpha=0.8)\n\nplt.title(\"Data\")\nplt.xlabel(\"x1\"); plt.ylabel(\"x2\")\nplt.grid(True, linestyle=\":\", linewidth=0.8)\nplt.legend()\nplt.show()\n</code></pre> <p> </p> <p>Distribui\u00e7\u00e3o das classes</p> <p>Observando o gr\u00e1fico de dispers\u00e3o obtido:</p> <ul> <li> <p>Classe 0 (azul): est\u00e1 localizada \u00e0 esquerda, centrada em torno de <code>x1 \u2248 2</code>.   Apresenta grande varia\u00e7\u00e3o em <code>x2</code>, formando uma nuvem vertical que vai de valores negativos at\u00e9 acima de 7.  </p> </li> <li> <p>Classe 1 (laranja): posicionada mais ao centro, em <code>x1 \u2248 5</code>.   Distribui-se em n\u00edveis mais altos de <code>x2</code> (acima de 5), com dispers\u00e3o consider\u00e1vel, o que gera sobreposi\u00e7\u00e3o com a Classe 0 em algumas regi\u00f5es.  </p> </li> <li> <p>Classe 2 (verde): centrada em <code>x1 \u2248 8</code> e valores baixos de <code>x2</code> (por volta de 1).   \u00c9 a classe mais compacta, com baixa dispers\u00e3o, o que facilita sua identifica\u00e7\u00e3o. No entanto, apresenta certa proximidade com a Classe 1 na regi\u00e3o de fronteira.  </p> </li> <li> <p>Classe 3 (vermelha): bem afastada das demais, em <code>x1 \u2248 15</code>.   Mesmo com varia\u00e7\u00e3o em <code>x2</code>, mant\u00e9m-se completamente separada das outras classes, o que torna sua classifica\u00e7\u00e3o a mais simples do conjunto.</p> </li> </ul>"},{"location":"data/exercicio1/exercicio1/#conclusoes-sobre-separabilidade","title":"Conclus\u00f5es sobre separabilidade","text":"<ul> <li>Existe uma ordem clara das classes ao longo do eixo <code>x1</code>: C0 \u2192 C1 \u2192 C2 \u2192 C3.  </li> <li>Por\u00e9m, as classes 0 e 1 apresentam sobreposi\u00e7\u00e3o em parte do espa\u00e7o (principalmente entre <code>x1=2</code> e <code>x1=5</code>), o que dificulta a separa\u00e7\u00e3o por um limite totalmente linear.  </li> <li>A Classe 2 \u00e9 bem definida e isolada verticalmente, embora esteja pr\u00f3xima da Classe 1 na horizontal.  </li> <li>A Classe 3 est\u00e1 completamente isolada, sendo a mais f\u00e1cil de separar.  </li> </ul>"},{"location":"data/exercicio1/exercicio1/#etapa-4-definicao-de-fronteiras-lineares-simples","title":"Etapa 4 \u2014 Defini\u00e7\u00e3o de Fronteiras Lineares Simples","text":"<p>Para explorar a separabilidade dos dados, tracei fronteiras lineares verticais ao longo do eixo <code>x1</code>, representando limites de decis\u00e3o iniciais entre as classes.</p> <pre><code>xlines = [\n    (2 + 5) / 2,   \n    (5 + 8) / 2,   \n    (8 + 15) / 2   \n]\n\nplt.figure(figsize=(7,5))\nplt.scatter(c0[:,0], c0[:,1], label=\"Class 0\", s=18, alpha=0.8)\nplt.scatter(c1[:,0], c1[:,1], label=\"Class 1\", s=18, alpha=0.8)\nplt.scatter(c2[:,0], c2[:,1], label=\"Class 2\", s=18, alpha=0.8)\nplt.scatter(c3[:,0], c3[:,1], label=\"Class 3\", s=18, alpha=0.8)\n\nfor x in xlines:\n    plt.axvline(x, linestyle=\"--\", linewidth=2)\n\nplt.title(\"Scatter + fronteiras lineares (simples)\")\nplt.xlabel(\"x1\"); plt.ylabel(\"x2\")\nplt.grid(True, linestyle=\":\", linewidth=0.8)\nplt.legend()\nplt.show()\n</code></pre> <p> </p> <p>Divis\u00e3o das classes</p>"},{"location":"data/exercicio1/exercicio1/#analise","title":"An\u00e1lise","text":"<ul> <li>Esse m\u00e9todo de fronteira \u00e9 simples e intuitivo, funcionando bem quando as classes est\u00e3o distribu\u00eddas principalmente em torno de valores diferentes de <code>x1</code>.  </li> <li>No entanto, ele n\u00e3o considera a dispers\u00e3o em <code>x2</code>, o que gera problemas de sobreposi\u00e7\u00e3o:  </li> <li>Classes 0 e 1 continuam com regi\u00f5es de confus\u00e3o, pois se sobrep\u00f5em verticalmente.  </li> <li>Classes 1 e 2 tamb\u00e9m podem apresentar mistura em regi\u00f5es pr\u00f3ximas \u00e0 linha divis\u00f3ria.  </li> <li>A Classe 3, por estar bem afastada, \u00e9 separada de forma perfeita com esse limite linear.</li> </ul>"},{"location":"data/exercicio1/exercicio1/#implicacao-para-redes-neurais","title":"Implica\u00e7\u00e3o para redes neurais","text":"<ul> <li>Um modelo linear simples poderia usar limites parecidos com estes para classificar os dados.  </li> <li>Por\u00e9m, como h\u00e1 sobreposi\u00e7\u00e3o entre classes, uma rede neural com m\u00faltiplas camadas e fun\u00e7\u00f5es de ativa\u00e7\u00e3o n\u00e3o lineares teria mais flexibilidade para ajustar fronteiras curvas ou inclinadas, capturando melhor as regi\u00f5es de confus\u00e3o.</li> </ul>"},{"location":"data/exercicio2/exercicio2/","title":"Exercicio 2 - Data","text":""},{"location":"data/exercicio2/exercicio2/#objetivo","title":"Objetivo","text":"<p>O objetivo deste exerc\u00edcio foi criar dois conjuntos de dados em 5 dimens\u00f5es (Classes A e B), cada um com 500 amostras, a partir de distribui\u00e7\u00f5es normais multivariadas. Em seguida, reduzir a dimensionalidade com PCA para 2D e analisar a separabilidade linear.  </p> <p>Minha hip\u00f3tese inicial era de que, como as classes possuem covari\u00e2ncias diferentes, a fronteira \u00f3tima n\u00e3o seria linear, representando um desafio para modelos simples como Perceptron ou Regress\u00e3o Log\u00edstica, e justificando o uso de modelos mais complexos (ex: redes neurais).</p>"},{"location":"data/exercicio2/exercicio2/#etapa-1-definicao-dos-parametros-e-semente-do-gerador","title":"Etapa 1 \u2014 Defini\u00e7\u00e3o dos par\u00e2metros e semente do gerador","text":"<p>Aqui eu preparei o gerador de n\u00fameros aleat\u00f3rios e defini os par\u00e2metros das distribui\u00e7\u00f5es normais multivariadas para as duas classes (A e B).</p> <ul> <li> <p><code>rng = np.random.default_rng(42)</code>   Criei um gerador pseudoaleat\u00f3rio com semente 42 para garantir reprodutibilidade. Isso significa que, ao rodar o c\u00f3digo v\u00e1rias vezes, os mesmos dados ser\u00e3o gerados.</p> </li> <li> <p><code>mu_A</code> e <code>mu_B</code>   S\u00e3o os vetores de m\u00e9dias das classes, cada um com 5 dimens\u00f5es.  </p> </li> <li>Classe A \u00e9 centrada na origem.  </li> <li> <p>Classe B \u00e9 deslocada em rela\u00e7\u00e3o \u00e0 A (todas as m\u00e9dias iguais a 1.5).</p> </li> <li> <p><code>Sigma_A</code> e <code>Sigma_B</code>   S\u00e3o as matrizes de covari\u00e2ncia (5\u00d75) que controlam o espalhamento e as correla\u00e7\u00f5es entre as vari\u00e1veis de cada classe.  </p> </li> <li>Em A, h\u00e1 correla\u00e7\u00f5es positivas entre algumas vari\u00e1veis.  </li> <li>Em B, h\u00e1 correla\u00e7\u00f5es negativas e vari\u00e2ncias maiores.  </li> </ul> <p>Esses par\u00e2metros ser\u00e3o usados na fun\u00e7\u00e3o <code>rng.multivariate_normal</code> para gerar os pontos de cada classe na etapa seguinte.</p> <pre><code>rng = np.random.default_rng(42)\n\nmu_A = np.array([0., 0., 0., 0., 0.])\nSigma_A = np.array([\n    [1.0, 0.8, 0.1, 0.0, 0.0],\n    [0.8, 1.0, 0.3, 0.0, 0.0],\n    [0.1, 0.3, 1.0, 0.5, 0.0],\n    [0.0, 0.0, 0.5, 1.0, 0.2],\n    [0.0, 0.0, 0.0, 0.2, 1.0],\n])\n\nmu_B = np.array([1.5, 1.5, 1.5, 1.5, 1.5])\nSigma_B = np.array([\n    [1.5, -0.7, 0.2, 0.0, 0.0],\n    [-0.7, 1.5, 0.4, 0.0, 0.0],\n    [0.2, 0.4, 1.5, 0.6, 0.0],\n    [0.0, 0.0, 0.6, 1.5, 0.3],\n    [0.0, 0.0, 0.0, 0.3, 1.5],\n])\n</code></pre>"},{"location":"data/exercicio2/exercicio2/#etapa-2-amostragem-dos-dados-e-criacao-dos-rotulos","title":"Etapa 2 \u2014 Amostragem dos dados e cria\u00e7\u00e3o dos r\u00f3tulos","text":"<p>Nesta parte eu realmente gerei os pontos das duas classes e preparei os conjuntos de dados e r\u00f3tulos.</p> <ul> <li> <p><code>nA = nB = 500</code>   Defini que cada classe ter\u00e1 500 amostras, totalizando 1000 pontos.</p> </li> <li> <p><code>rng.multivariate_normal(mean=..., cov=..., size=...)</code>   Fun\u00e7\u00e3o que gera amostras de uma distribui\u00e7\u00e3o normal multivariada.  </p> </li> <li><code>mean</code> \u2192 vetor de m\u00e9dias da classe.  </li> <li><code>cov</code> \u2192 matriz de covari\u00e2ncia que define vari\u00e2ncias e correla\u00e7\u00f5es.  </li> <li> <p><code>size</code> \u2192 n\u00famero de amostras a serem geradas.   Assim, <code>A</code> cont\u00e9m os pontos da Classe A (500\u00d75) e <code>B</code> os da Classe B (500\u00d75).</p> </li> <li> <p><code>np.vstack([A, B])</code>   Empilhei os dois conjuntos verticalmente, formando a matriz <code>X</code> com shape (1000, 5).</p> </li> <li> <p><code>np.hstack([np.zeros(nA, int), np.ones(nB, int)])</code>   Criei o vetor de r\u00f3tulos <code>y</code>:  </p> </li> <li><code>0</code> representa a Classe A.  </li> <li><code>1</code> representa a Classe B.   Isso me permite identificar de qual classe cada ponto pertence.</li> </ul> <p>Com isso, foi finalizada a gera\u00e7\u00e3o do dataset 5D completo, pronto para redu\u00e7\u00e3o de dimensionalidade e an\u00e1lise.</p> <pre><code>nA = nB = 500\nA = rng.multivariate_normal(mean=mu_A, cov=Sigma_A, size=nA)\nB = rng.multivariate_normal(mean=mu_B, cov=Sigma_B, size=nB)\n\nX = np.vstack([A, B])           \ny = np.hstack([np.zeros(nA, int), np.ones(nB, int)])\n</code></pre>"},{"location":"data/exercicio2/exercicio2/#etapa-3-reducao-de-dimensionalidade-com-pca-5d-2d","title":"Etapa 3 \u2014 Redu\u00e7\u00e3o de dimensionalidade com PCA (5D \u2192 2D)","text":"<p>Nesta etapa eu utilizei o PCA (Principal Component Analysis) para reduzir os dados de 5 dimens\u00f5es para apenas 2, permitindo visualiza\u00e7\u00e3o em gr\u00e1fico de dispers\u00e3o.</p> <ul> <li><code>pca = PCA(n_components=2, random_state=42)</code>   Criei um objeto PCA que mant\u00e9m apenas 2 componentes principais.  </li> <li> <p>O PCA encontra dire\u00e7\u00f5es de maior vari\u00e2ncia nos dados, ignorando r\u00f3tulos de classe.</p> </li> <li> <p><code>X2 = pca.fit_transform(X)</code>   Aqui eu ajustei o PCA aos dados 5D (<code>fit</code>) e projetei os pontos nesses dois eixos principais (<code>transform</code>).   O resultado \u00e9 uma matriz <code>X2</code> com shape (1000, 2), representando cada amostra em duas dimens\u00f5es (PC1 e PC2).</p> </li> <li> <p><code>df[\"pc1\"] = X2[:, 0]</code> e <code>df[\"pc2\"] = X2[:, 1]</code>   Adicionei as duas novas colunas ao DataFrame para facilitar visualiza\u00e7\u00e3o e plotagem.</p> </li> <li> <p><code>pca.explained_variance_ratio_</code>   Essa fun\u00e7\u00e3o retorna quanto da vari\u00e2ncia total dos dados originais foi preservada por cada componente.  </p> </li> <li>O <code>print</code> mostra a vari\u00e2ncia explicada por PC1 e PC2 separadamente.  </li> <li>Tamb\u00e9m calculei a soma, para verificar quanta informa\u00e7\u00e3o 5D conseguimos reter em 2D.</li> </ul> <pre><code>pca = PCA(n_components=2, random_state=42)\nX2 = pca.fit_transform(X)\ndf[\"pc1\"] = X2[:, 0]\ndf[\"pc2\"] = X2[:, 1]\n\nprint(\"Vari\u00e2ncia explicada (PC1, PC2):\", np.round(pca.explained_variance_ratio_, 3))\nprint(\"Soma da vari\u00e2ncia explicada:\", np.round(pca.explained_variance_ratio_.sum(), 3))\n</code></pre>"},{"location":"data/exercicio2/exercicio2/#etapa-4-visualizacao-grafica-das-classes-no-espaco-2d","title":"Etapa 4 \u2014 Visualiza\u00e7\u00e3o gr\u00e1fica das classes no espa\u00e7o 2D","text":"<p>Nesta etapa eu fiz a visualiza\u00e7\u00e3o final dos dados ap\u00f3s a redu\u00e7\u00e3o de dimensionalidade com PCA. Usei o Matplotlib para criar um gr\u00e1fico de dispers\u00e3o que mostra as duas classes projetadas no plano formado pelos dois componentes principais (PC1 e PC2).</p> <p>Esse gr\u00e1fico permite comparar visualmente como as duas classes se distribuem em 2D e perceber se existe ou n\u00e3o separa\u00e7\u00e3o linear entre elas.</p> <pre><code>plt.figure(figsize=(7, 5))\nplt.scatter(df.loc[df[\"class\"] == 0, \"pc1\"], df.loc[df[\"class\"] == 0, \"pc2\"],\n            s=14, alpha=0.8, label=\"Classe A\")\nplt.scatter(df.loc[df[\"class\"] == 1, \"pc1\"], df.loc[df[\"class\"] == 1, \"pc2\"],\n            s=14, alpha=0.8, label=\"Classe B\")\nplt.title(\"PCA (5D \u2192 2D): Classe A vs Classe B\")\nplt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\nplt.grid(True, linestyle=\":\", linewidth=0.8)\nplt.legend()\nplt.show()\n</code></pre> <p> </p> <p>Distribui\u00e7\u00e3o das classes</p> <p>Separabilidade linear (an\u00e1lise final):</p> <p>Na proje\u00e7\u00e3o em 2D, \u00e9 poss\u00edvel perceber que as duas classes n\u00e3o ficam totalmente separadas: h\u00e1 regi\u00f5es onde os pontos de A e B se misturam. Mesmo considerando os dados no espa\u00e7o original de 5 dimens\u00f5es, a forma como as duas classes est\u00e3o distribu\u00eddas faz com que uma linha reta n\u00e3o seja suficiente para dividi-las corretamente.</p> <p>Isso significa que modelos simples que trabalham apenas com separa\u00e7\u00f5es retas, como o Perceptron, n\u00e3o conseguem representar bem esse tipo de situa\u00e7\u00e3o. Por outro lado, modelos mais avan\u00e7ados, como redes neurais, conseguem criar fronteiras curvas e mais flex\u00edveis, o que permite distinguir melhor as duas classes mesmo quando elas n\u00e3o est\u00e3o separadas de forma simples.</p>"},{"location":"data/exercicio3/exercicio3/","title":"Exerc\u00edcio 3 \u2014 DATA","text":""},{"location":"data/exercicio3/exercicio3/#objetivo","title":"Objetivo","text":"<p>O objetivo \u00e9 preparar o conjunto de dados Spaceship Titanic (train.csv do Kaggle) para uso em uma rede neural que utiliza a fun\u00e7\u00e3o de ativa\u00e7\u00e3o tanh.  </p> <p>A seguir, realizei o passo a passo de carregamento, explora\u00e7\u00e3o, tratamento de nulos, codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas e padroniza\u00e7\u00e3o de num\u00e9ricas, al\u00e9m de visualizar o impacto do pr\u00e9-processamento.</p>"},{"location":"data/exercicio3/exercicio3/#etapa-1-carregamento-e-descricao-do-dataset","title":"Etapa 1 \u2014 Carregamento e descri\u00e7\u00e3o do dataset","text":"<p>O arquivo <code>train.csv</code> cont\u00e9m cerca de 8700 passageiros. Cada linha representa um passageiro, com informa\u00e7\u00f5es pessoais, dados de viagem e gastos. A coluna <code>Transported</code> \u00e9 o alvo (True/False), indicando se o passageiro foi transportado para outra dimens\u00e3o.</p> <p>Principais tipos de vari\u00e1veis:</p> <ul> <li>Identifica\u00e7\u00e3o: <code>PassengerId</code>, <code>Name</code> .</li> <li>Categ\u00f3ricas: <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Cabin</code>, <code>Destination</code>, <code>VIP</code>.</li> <li>Num\u00e9ricas: <code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>.</li> <li>Alvo: <code>Transported</code>.</li> </ul> <pre><code>import pandas as pd\n\ndf = pd.read_csv(\"data/train.csv\")\ndisplay(df.head())\nprint(df.info())\nprint(df.isnull().sum())\n</code></pre>"},{"location":"data/exercicio3/exercicio3/#valores-ausentes","title":"Valores ausentes","text":"<p>Ap\u00f3s carregar o dataset <code>train.csv</code>, percebi que ele possui 8693 linhas e 14 colunas. Algumas vari\u00e1veis apresentam valores ausentes, enquanto outras est\u00e3o completas:</p> <ul> <li>Sem valores ausentes:</li> <li><code>PassengerId</code> \u2192 identificador \u00fanico de cada passageiro.  </li> <li> <p><code>Transported</code> \u2192 vari\u00e1vel alvo (true ou false para saber se o passageiro foi transportado).</p> </li> <li> <p>Com valores ausentes:</p> </li> <li><code>HomePlanet</code> (201) \u2192 planeta de origem.  </li> <li><code>CryoSleep</code> (217) \u2192 se o passageiro estava em criossuspens\u00e3o.  </li> <li><code>Cabin</code> (199) \u2192 cabine onde estava hospedado.  </li> <li><code>Destination</code> (182) \u2192 planeta de destino.  </li> <li><code>Age</code> (179) \u2192 idade do passageiro.  </li> <li><code>VIP</code> (203) \u2192 se contratou servi\u00e7o VIP.  </li> <li><code>RoomService</code> (181), <code>FoodCourt</code> (183), <code>ShoppingMall</code> (208), <code>Spa</code> (183), <code>VRDeck</code> (188) \u2192 gastos.  </li> <li><code>Name</code> (200) \u2192 nome do passageiro.</li> </ul>"},{"location":"data/exercicio3/exercicio3/#observacoes","title":"Observa\u00e7\u00f5es","text":"<ul> <li>O conjunto apresenta valores faltantes em quase todas as colunas de entrada.  </li> <li>O percentual de valores ausentes em cada coluna \u00e9 relativamente pequeno (entre 2% e 3% do total de linhas), ou seja, \u00e9 vi\u00e1vel aplicar t\u00e9cnicas de preenchimento  em vez de descartar linhas inteiras.  </li> </ul>"},{"location":"data/exercicio3/exercicio3/#etapa-2-definicao-dos-tipos-de-variaveis","title":"Etapa 2 \u2014 Defini\u00e7\u00e3o dos tipos de vari\u00e1veis","text":"<ul> <li>Num\u00e9ricas: <code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>.  </li> <li>Categ\u00f3ricas: <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Cabin</code>, <code>Destination</code>, <code>VIP</code>.  </li> <li>Alvo: <code>Transported</code>.</li> </ul>"},{"location":"data/exercicio3/exercicio3/#etapa-3-tratamento-de-valores-ausentes","title":"Etapa 3 \u2014 Tratamento de valores ausentes","text":"<p>Pelo <code>df.info()</code> e <code>df.isnull().sum()</code>:</p> <ul> <li>H\u00e1 nulos em quase todas as colunas de entrada (entre ~179 e ~217 linhas por coluna, \u22482%\u20133% do total de 8693).</li> </ul> <p>Estrat\u00e9gia adotada:</p> <ol> <li> <p>Categ\u00f3ricas (<code>HomePlanet</code>, <code>CryoSleep</code>, <code>Cabin</code>, <code>Destination</code>, <code>VIP</code>):</p> </li> <li> <p>Preencher com a moda (valor mais frequente).</p> </li> <li> <p>Para <code>Cabin</code>, al\u00e9m de preencher, separar em <code>Deck</code>/<code>Num</code>/<code>Side</code> (formato <code>deck/num/side</code>), pois \u00e9 uma string composta que carrega informa\u00e7\u00e3o \u00fatil.</p> </li> <li> <p>Num\u00e9ricas (<code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>):</p> </li> <li> <p>Preencher com a mediana (robusta a outliers).</p> </li> <li> <p>Regra de neg\u00f3cio adicional: se <code>CryoSleep == True</code>, os gastos deveriam ser zero (passageiro confinado \u00e0 cabine). Assim, nulos nos gastos para quem est\u00e1 em <code>CryoSleep</code> ser\u00e3o imputados com 0; os demais, com mediana.</p> </li> </ol>"},{"location":"data/exercicio3/exercicio3/#etapa-31-preparos-para-imputacao","title":"Etapa 3.1 \u2014 Preparos para imputa\u00e7\u00e3o","text":"<p>Antes de imputar:</p> <ul> <li> <p>Defino listas auxiliares de colunas.</p> </li> <li> <p>Converto <code>CryoSleep</code> e <code>VIP</code> para booleanos/bits depois de preencher (eles vieram como <code>object</code> por causa dos NaNs).</p> </li> <li> <p>Para <code>Cabin</code>, separo em tr\u00eas colunas (<code>Deck</code>, <code>Num</code>, <code>Side</code>), imputo <code>Deck</code>/<code>Side</code> com a moda e <code>Num</code> com a mediana (num\u00e9rica).</p> </li> </ul> <pre><code>num_cols = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\ncat_cols = [\"HomePlanet\", \"CryoSleep\", \"Cabin\", \"Destination\", \"VIP\"]  # Cabin ser\u00e1 expandida\ntarget = \"Transported\"\n\ncabin_split = df[\"Cabin\"].str.split(\"/\", expand=True)\ndf[\"Deck\"] = cabin_split[0]\ndf[\"Num\"]  = pd.to_numeric(cabin_split[1], errors=\"coerce\")  # num\u00e9rico\ndf[\"Side\"] = cabin_split[2]\n\ncat_cols_expanded = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Deck\", \"Side\"]\nnum_cols_expanded = num_cols + [\"Num\"]\n</code></pre>"},{"location":"data/exercicio3/exercicio3/#etapa-32-imputacao-das-categoricas","title":"Etapa 3.2 \u2014 Imputa\u00e7\u00e3o das categ\u00f3ricas","text":"<p>Regra: preencher categ\u00f3ricas com a moda (valor mais frequente). Depois, padronizo <code>CryoSleep</code> e <code>VIP</code> para inteiros 0/1 (necess\u00e1rio para modelos e para aplicar a regra dos gastos = 0 se em criossono).</p> <pre><code>for col in [\"HomePlanet\", \"Destination\", \"Deck\", \"Side\", \"CryoSleep\", \"VIP\"]:\n    df[col] = df[col].fillna(df[col].mode()[0])\n\ndef to_bool01(series):\n    return (\n        series\n        .replace({True: 1, False: 0, \"True\": 1, \"False\": 0, \"TRUE\": 1, \"FALSE\": 0})\n        .astype(int)\n    )\n\ndf[\"CryoSleep\"] = to_bool01(df[\"CryoSleep\"])\ndf[\"VIP\"]       = to_bool01(df[\"VIP\"])\n\ndf[\"Transported\"] = df[\"Transported\"].astype(int)\n</code></pre>"},{"location":"data/exercicio3/exercicio3/#etapa-33-imputacao-das-numericas","title":"Etapa 3.3 \u2014 Imputa\u00e7\u00e3o das num\u00e9ricas","text":"<p>Regra geral: imputar mediana. Regra de neg\u00f3cio adicional para gastos: se <code>CryoSleep == 1</code>, nulos em gastos (<code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>) viram 0; os demais nulos seguem para mediana.</p> <p>Para <code>Num</code> (n\u00famero da cabine, derivado de <code>Cabin</code>), uso mediana.</p> <pre><code>spend_cols = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n\nfor col in spend_cols:\n    mask = (df[\"CryoSleep\"] == 1) &amp; (df[col].isna())\n    df.loc[mask, col] = 0.0\n\nfor col in num_cols_expanded:\n    df[col] = df[col].fillna(df[col].median())\n</code></pre>"},{"location":"data/exercicio3/exercicio3/#etapa-34-limpeza-final-desta-etapa","title":"Etapa 3.4 \u2014 Limpeza final desta etapa","text":"<ul> <li><code>Cabin</code> original \u00e9 removida (substitu\u00edda por <code>Deck</code>, <code>Num</code>, <code>Side</code>).</li> <li><code>Name</code> n\u00e3o ser\u00e1 usado como atributo neste exerc\u00edcio (texto livre), ent\u00e3o removo.</li> <li>Fa\u00e7o uma checagem final para garantir zero valores ausentes nas colunas que seguem para o modelo.</li> </ul> <pre><code>df = df.drop(columns=[\"Cabin\", \"Name\"])\n\nmissing_total = df.isnull().sum().sum()\nprint(f\"valores ausentes: {missing_total}\")\n</code></pre>"},{"location":"data/exercicio3/exercicio3/#etapa-35-comentarios-e-justificativas","title":"Etapa 3.5 \u2014 Coment\u00e1rios e justificativas","text":"<ul> <li>Moda nas categ\u00f3ricas: mant\u00e9m a coer\u00eancia dos dados e evita criar categorias artificiais com baixa frequ\u00eancia.</li> <li>Mediana nas num\u00e9ricas: \u00e9 robusta a valores extremos (outliers), comuns nas colunas de gastos.</li> <li>Regra de gastos = 0 em CryoSleep: condiz com a defini\u00e7\u00e3o do problema (passageiros em criossono ficam na cabine e n\u00e3o consomem servi\u00e7os).</li> <li>Separar <code>Cabin</code> em <code>Deck</code>/<code>Num</code>/<code>Side</code>: aproveita a estrutura da informa\u00e7\u00e3o, em vez de trat\u00e1-la como uma string opaca. <code>Deck</code> e <code>Side</code> entram como categ\u00f3ricas; <code>Num</code>, como num\u00e9rica.</li> <li>Remover <code>Name</code>: campo textual livre, de pouca utilidade neste exerc\u00edcio de pr\u00e9-processamento para uma MLP com <code>tanh</code> (sem embeddings/PLN). Pode ser reintroduzido em projetos onde se extraem sobrenomes/grupos.</li> <li>Ap\u00f3s estas decis\u00f5es, o dataset est\u00e1 livre de nulos e pronto para codifica\u00e7\u00e3o categ\u00f3rica e escalonamento (pr\u00f3ximas etapas).</li> </ul>"},{"location":"data/exercicio3/exercicio3/#etapa-4-codificacao-de-variaveis-categoricas","title":"Etapa 4 \u2014 Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas","text":"<p>Para treinar uma rede neural, todas as entradas precisam estar em formato num\u00e9rico.</p> <ul> <li>Vari\u00e1veis bin\u00e1rias:  </li> <li><code>CryoSleep</code> e <code>VIP</code> j\u00e1 foram convertidas para 0/1.  </li> <li>Vari\u00e1veis multiclasse:  </li> <li><code>HomePlanet</code>, <code>Destination</code>, <code>Deck</code>, <code>Side</code> \u2192 apliquei One-Hot Encoding, criando colunas dummy (0/1).  </li> </ul> <p>Assim, todas as categorias foram transformadas em indicadores num\u00e9ricos sem introduzir ordens artificiais.</p> <pre><code>df = pd.get_dummies(df, columns=[\"HomePlanet\", \"Destination\", \"Deck\", \"Side\"], drop_first=True)\n\ndisplay(df.head())\n</code></pre>"},{"location":"data/exercicio3/exercicio3/#etapa-5-escalonamento-dos-atributos-numericos","title":"Etapa 5 \u2014 Escalonamento dos atributos num\u00e9ricos","text":"<p>A fun\u00e7\u00e3o de ativa\u00e7\u00e3o tanh \u00e9 centrada em zero e gera sa\u00eddas em [-1, 1]. Portanto, \u00e9 essencial que as vari\u00e1veis num\u00e9ricas estejam padronizadas para:</p> <ul> <li>m\u00e9dia = 0  </li> <li>desvio padr\u00e3o = 1  </li> </ul> <p>Isso melhora a estabilidade do treinamento e acelera a converg\u00eancia. Para isso, usei <code>StandardScaler</code> da biblioteca <code>scikit-learn</code>.</p> <pre><code>from sklearn.preprocessing import StandardScaler\n\nnum_cols_final = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Num\"]\n\nscaler = StandardScaler()\ndf[num_cols_final] = scaler.fit_transform(df[num_cols_final])\n\ndisplay(df[num_cols_final].head())\n</code></pre>"},{"location":"data/exercicio3/exercicio3/#etapa-6-visualizacao-do-impacto-do-pre-processamento","title":"Etapa 6 \u2014 Visualiza\u00e7\u00e3o do impacto do pr\u00e9-processamento","text":"<p>Para evidenciar a transforma\u00e7\u00e3o feita, comparei a distribui\u00e7\u00e3o de vari\u00e1veis num\u00e9ricas antes e depois do escalonamento:</p> <ul> <li>Idade (<code>Age</code>): mostra como foi centralizada em torno de zero e ajustada em escala.  </li> <li>Gasto em <code>FoodCourt</code>: mostra como valores muito altos foram reduzidos para uma escala padr\u00e3o, sem alterar a forma da distribui\u00e7\u00e3o.</li> </ul> <p>Isso comprova que os dados foram preparados corretamente para uso em uma rede neural com <code>tanh</code>.</p> <pre><code>import matplotlib.pyplot as plt\n\n# Dados originais para compara\u00e7\u00e3o\ndf_raw = pd.read_csv(\"data/train.csv\")\n\nfig, axes = plt.subplots(2, 2, figsize=(10,6))\n\n# Antes\naxes[0,0].hist(df_raw[\"Age\"].dropna(), bins=30, color=\"skyblue\")\naxes[0,0].set_title(\"Age (Antes)\")\n\naxes[0,1].hist(df_raw[\"FoodCourt\"].dropna(), bins=30, color=\"salmon\")\naxes[0,1].set_title(\"FoodCourt (Antes)\")\n\n# Depois\naxes[1,0].hist(df[\"Age\"], bins=30, color=\"skyblue\")\naxes[1,0].set_title(\"Age (Depois)\")\n\naxes[1,1].hist(df[\"FoodCourt\"], bins=30, color=\"salmon\")\naxes[1,1].set_title(\"FoodCourt (Depois)\")\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p> </p> <p>Compara\u00e7\u00e3o pr\u00e9-p\u00f3s processamento</p>"},{"location":"data/exercicio3/exercicio3/#importancia-do-pre-processamento","title":"Import\u00e2ncia do Pr\u00e9-processamento","text":""},{"location":"data/exercicio3/exercicio3/#variavel-age","title":"Vari\u00e1vel Age","text":"<ul> <li>Antes: a idade estava distribu\u00edda entre 0 e 80 anos, com concentra\u00e7\u00e3o principal entre 20 e 40.  </li> <li>Depois: ap\u00f3s a padroniza\u00e7\u00e3o, os valores passaram a variar aproximadamente entre -2 e +3, centralizados em torno de zero.  </li> <li>Impacto: a transforma\u00e7\u00e3o mant\u00e9m a forma da distribui\u00e7\u00e3o, mas coloca a vari\u00e1vel em uma escala adequada para a fun\u00e7\u00e3o de ativa\u00e7\u00e3o <code>tanh</code>, que trabalha melhor com valores pr\u00f3ximos de zero.</li> </ul>"},{"location":"data/exercicio3/exercicio3/#variavel-foodcourt","title":"Vari\u00e1vel FoodCourt","text":"<ul> <li>Antes: os gastos apresentavam valores de 0 at\u00e9 quase 30.000, mas altamente concentrados em torno de zero.  </li> <li>Depois: ap\u00f3s normaliza\u00e7\u00e3o/padroniza\u00e7\u00e3o, os valores foram reduzidos para uma faixa pr\u00f3xima de 0 a 18.  </li> <li>Impacto: isso evita que essa vari\u00e1vel, por estar em uma escala muito maior que as demais, dominasse o processo de treinamento da rede neural.</li> </ul>"},{"location":"data/exercicio3/exercicio3/#comparacao-geral","title":"Compara\u00e7\u00e3o Geral","text":"<ul> <li>O pr\u00e9-processamento preservou o padr\u00e3o das distribui\u00e7\u00f5es, mas ajustou suas escalas para torn\u00e1-las compar\u00e1veis.  </li> <li>Agora, cada vari\u00e1vel contribui de maneira mais equilibrada para o aprendizado, sem que uma tenha peso desproporcional apenas por conta da unidade de medida.  </li> <li>Al\u00e9m disso, como os valores foram centralizados (no caso de Age) e reduzidos (no caso de FoodCourt), a rede neural ter\u00e1 treinamento mais est\u00e1vel e eficiente, evitando satura\u00e7\u00e3o da fun\u00e7\u00e3o de ativa\u00e7\u00e3o <code>tanh</code>.</li> </ul>"},{"location":"data/exercicio3/exercicio3/#conclusao","title":"Conclus\u00e3o","text":"<p>O pr\u00e9-processamento foi essencial para:</p> <ul> <li>Reduzir diferen\u00e7as de escala entre atributos,  </li> <li>Adaptar os dados para o intervalo adequado da fun\u00e7\u00e3o de ativa\u00e7\u00e3o,  </li> <li>Garantir que todos os atributos tenham relev\u00e2ncia equilibrada na classifica\u00e7\u00e3o.</li> </ul>"},{"location":"metricas/main/","title":"Metricas","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> <p></p> <p></p> <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"},{"location":"mlp/main/","title":"MLP","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> </p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"perceptron/main/","title":"Perceptron","text":""},{"location":"perceptron/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica {\n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"perceptron/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"thisdocumentation/main/","title":"This documentation","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}